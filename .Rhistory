browseURL(metadata_relLx$case_page[2967])
case_page
case_page <- metadata_relLx$case_page[2967]
con_test <- try(parsed_case_page <- case_page %>%
read_html(), silent = TRUE)
# if true, weak connection...wait 1 minute, and then reconnect and parse the HTML page
if(class(con_test) == "try-error") {
print("reconecting in 1 minute!")
Sys.sleep(60)
parsed_case_page <- case_page %>%
read_html()
}
### scrape the case details table
md_table <- parsed_case_page %>%
html_node(xpath = "//table") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:")) %>%
t() %>%
as_tibble() %>%
set_names(.,
nm = .[1,] %>%
str_replace_all(., "[[:punct:]]|º", "") %>%
str_to_lower() %>%
str_replace_all(., "\\s+", "_")) %>%
slice(2) %>%
mutate_all(funs(str_replace_all(., "[[:cntrl:]]", "; ")))
parsed_case_page %>%
html_node(xpath = "//table") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:")) %>%
t() %>%
as_tibble()
parsed_case_page %>%
html_node(xpath = "//table") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:")) %>%
t() %>%
as_tibble() %>%
set_names(.,
nm = .[1,] %>%
str_replace_all(., "[[:punct:]]|º", "") %>%
str_to_lower() %>%
str_replace_all(., "\\s+", "_")) %>%
slice(2)
View(parsed_case_page %>%
html_node(xpath = "//table") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:")) %>%
t() %>%
as_tibble() %>%)
View(parsed_case_page %>%
html_node(xpath = "//table") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:")) %>%
t() %>%
as_tibble())
parsed_case_page %>%
html_node(xpath = "//table") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2)
View(parsed_case_page %>%
html_node(xpath = "//table") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2))
View(parsed_case_page %>%
html_node(xpath = "//table") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:$")) %>%
t() %>%
as_tibble())
relLx_data_raw <- map2(metadata_relLx$case_page, 1:length(metadata_relLx$case_page), function(case_page, n){
cat(paste0("\n\n", "scraping case ", n, "\n\n"))
## check the internet conection, and wait if it is weak. If not, just parse the HTML page
con_test <- try(parsed_case_page <- case_page %>%
read_html(), silent = TRUE)
# if true, weak connection...wait 1 minute, and then reconnect and parse the HTML page
if(class(con_test) == "try-error") {
print("reconecting in 1 minute!")
Sys.sleep(60)
parsed_case_page <- case_page %>%
read_html()
}
### scrape the case details table
md_table <- parsed_case_page %>%
html_node(xpath = "//table") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:$")) %>%
t() %>%
as_tibble() %>%
set_names(.,
nm = .[1,] %>%
str_replace_all(., "[[:punct:]]|º", "") %>%
str_to_lower() %>%
str_replace_all(., "\\s+", "_")) %>%
slice(2) %>%
mutate_all(funs(str_replace_all(., "[[:cntrl:]]", "; ")))
### Next, we check if the "integral text" row exists. If yes, we scrape it and add it to the table above.
dec_table <- parsed_case_page %>%
html_node(xpath = "//table[2]") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:")) %>%
t() %>%
as_tibble() %>%
set_names(.,
nm = .[1,] %>%
str_replace_all(., "[[:punct:]]|º", "") %>%
str_to_lower() %>%
str_replace_all(., "\\s+", "_")) %>%
slice(2)
if(ncol(dec_table) == 1){
md_table$decisao_texto <- pull(dec_table[1])
} else {
md_table$decisao_texto <- NA_character_
}
case_table <- md_table %>%
mutate(case_page = case_page,
dateOfAccess = Sys.Date()) %>%
select(relator, palavras_chave = descritores, data_do_acordao = "data_do_acordão", votacao = "votação", meio_processual, sumario = "sumário", decisao_texto, everything())
print(case_table, sample(ncol(case_table), 4))
return(case_table)
Sys.sleep(runif(3,2,4))
})
beepr::beep(8)
## export it
save(relLx_data_raw,
file = "interm_data/raw_relLx_data.Rdata")
write.csv(relLx_data_raw,
file = "interm_data/raw_relLx_data.csv")
md_table <- parsed_case_page %>%
html_node(xpath = "//table") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:$")) %>%
t() %>%
as_tibble() %>%
set_names(.,
nm = .[1,] %>%
str_replace_all(., "[[:punct:]]|º", "") %>%
str_to_lower() %>%
str_replace_all(., "\\s+", "_")) %>%
slice(2) %>%
mutate_all(funs(str_replace_all(., "[[:cntrl:]]", "; ")))
### Next, we check if the "integral text" row exists. If yes, we scrape it and add it to the table above.
dec_table <- parsed_case_page %>%
html_node(xpath = "//table[2]") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:")) %>%
t() %>%
as_tibble() %>%
set_names(.,
nm = .[1,] %>%
str_replace_all(., "[[:punct:]]|º", "") %>%
str_to_lower() %>%
str_replace_all(., "\\s+", "_")) %>%
slice(2)
if(ncol(dec_table) == 1){
md_table$decisao_texto <- pull(dec_table[1])
} else {
md_table$decisao_texto <- NA_character_
}
md_table %>%
mutate(case_page = case_page,
dateOfAccess = Sys.Date()) %>%
select(relator, palavras_chave = descritores, data_do_acordao = "data_do_acordão", votacao = "votação", meio_processual, sumario = "sumário", decisao_texto, everything())
browseURL(case_page)
names(md_table)
relLx_data_raw <- map2(metadata_relLx$case_page, 1:length(metadata_relLx$case_page), function(case_page, n){
cat(paste0("\n\n", "scraping case ", n, "\n\n"))
## check the internet conection, and wait if it is weak. If not, just parse the HTML page
con_test <- try(parsed_case_page <- case_page %>%
read_html(), silent = TRUE)
# if true, weak connection...wait 1 minute, and then reconnect and parse the HTML page
if(class(con_test) == "try-error") {
print("reconecting in 1 minute!")
Sys.sleep(60)
parsed_case_page <- case_page %>%
read_html()
}
### scrape the case details table
md_table <- parsed_case_page %>%
html_node(xpath = "//table") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:$")) %>%
t() %>%
as_tibble() %>%
set_names(.,
nm = .[1,] %>%
str_replace_all(., "[[:punct:]]|º", "") %>%
str_to_lower() %>%
str_replace_all(., "\\s+", "_")) %>%
slice(2) %>%
mutate_all(funs(str_replace_all(., "[[:cntrl:]]", "; ")))
### Next, we check if the "integral text" row exists. If yes, we scrape it and add it to the table above.
dec_table <- parsed_case_page %>%
html_node(xpath = "//table[2]") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:")) %>%
t() %>%
as_tibble() %>%
set_names(.,
nm = .[1,] %>%
str_replace_all(., "[[:punct:]]|º", "") %>%
str_to_lower() %>%
str_replace_all(., "\\s+", "_")) %>%
slice(2)
if(ncol(dec_table) == 1){
md_table$decisao_texto <- pull(dec_table[1])
} else {
md_table$decisao_texto <- NA_character_
}
case_table <- md_table %>%
mutate(case_page = case_page,
dateOfAccess = Sys.Date()) %>%
select(data_do_acordao = "data_do_acordão", relator, decisao = "decisão", votacao = "votação", palavras_chave = descritores, meio_processual, sumario = "sumário", decisao_texto, one_of("decisão_texto_parcial", "decisão_texto_integral"), dateOfAccess, case_page)
print(case_table, sample(ncol(case_table), 4))
return(case_table)
Sys.sleep(runif(3,2,4))
})
beepr::beep(8)
## export it
save(relLx_data_raw,
file = "interm_data/raw_relLx_data.Rdata")
write.csv(relLx_data_raw,
file = "interm_data/raw_relLx_data.csv")
relLx_data_raw <- map2(metadata_relLx$case_page, 1:length(metadata_relLx$case_page), function(case_page, n){
cat(paste0("\n\n", "scraping case ", n, "\n\n"))
## check the internet conection, and wait if it is weak. If not, just parse the HTML page
con_test <- try(parsed_case_page <- case_page %>%
read_html(), silent = TRUE)
# if true, weak connection...wait 1 minute, and then reconnect and parse the HTML page
if(class(con_test) == "try-error") {
print("reconecting in 1 minute!")
Sys.sleep(60)
parsed_case_page <- case_page %>%
read_html()
}
### scrape the case details table
md_table <- parsed_case_page %>%
html_node(xpath = "//table") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:$")) %>%
t() %>%
as_tibble() %>%
set_names(.,
nm = .[1,] %>%
str_replace_all(., "[[:punct:]]|º", "") %>%
str_to_lower() %>%
str_replace_all(., "\\s+", "_")) %>%
slice(2) %>%
mutate_all(funs(str_replace_all(., "[[:cntrl:]]", "; ")))
### Next, we check if the "integral text" row exists. If yes, we scrape it and add it to the table above.
dec_table <- parsed_case_page %>%
html_node(xpath = "//table[2]") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:")) %>%
t() %>%
as_tibble() %>%
set_names(.,
nm = .[1,] %>%
str_replace_all(., "[[:punct:]]|º", "") %>%
str_to_lower() %>%
str_replace_all(., "\\s+", "_")) %>%
slice(2)
if(ncol(dec_table) == 1){
md_table$decisao_texto <- pull(dec_table[1])
} else {
md_table$decisao_texto <- NA_character_
}
case_table <- md_table %>%
mutate(case_page = case_page,
dateOfAccess = Sys.Date()) %>%
select(data_do_acordao = "data_do_acordão", relator, decisao = "decisão", votacao = "votação", palavras_chave = descritores, meio_processual, sumario = "sumário", decisao_texto, one_of("decisão_texto_parcial", "decisão_texto_integral"), dateOfAccess, case_page)
print(case_table, sample(ncol(case_table), 4))
return(case_table)
Sys.sleep(runif(2,1,3))
})
beepr::beep(8)
## export it
save(relLx_data_raw,
file = "interm_data/raw_relLx_data.Rdata")
write.csv(relLx_data_raw,
file = "interm_data/raw_relLx_data.csv")
print(case_table, sample(1:ncol(case_table), 4))
return(case_table)
print(case_table, sample(1:ncol(case_table), 4))
return(case_table)
print(case_table, sample(1:ncol(case_table), 4))
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
sample(1:ncol(case_table), 4)
print(case_table[,sample(1:ncol(case_table), 4)])
print(case_table[,sample(1:ncol(case_table), 4)])
relLx_data_raw <- map2(metadata_relLx$case_page, 1:length(metadata_relLx$case_page), function(case_page, n){
cat(paste0("\n\n", "scraping case ", n, "\n\n"))
## check the internet conection, and wait if it is weak. If not, just parse the HTML page
con_test <- try(parsed_case_page <- case_page %>%
read_html(), silent = TRUE)
# if true, weak connection...wait 1 minute, and then reconnect and parse the HTML page
if(class(con_test) == "try-error") {
print("reconecting in 1 minute!")
Sys.sleep(60)
parsed_case_page <- case_page %>%
read_html()
}
### scrape the case details table
md_table <- parsed_case_page %>%
html_node(xpath = "//table") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:$")) %>%
t() %>%
as_tibble() %>%
set_names(.,
nm = .[1,] %>%
str_replace_all(., "[[:punct:]]|º", "") %>%
str_to_lower() %>%
str_replace_all(., "\\s+", "_")) %>%
slice(2) %>%
mutate_all(funs(str_replace_all(., "[[:cntrl:]]", "; ")))
### Next, we check if the "integral text" row exists. If yes, we scrape it and add it to the table above.
dec_table <- parsed_case_page %>%
html_node(xpath = "//table[2]") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:")) %>%
t() %>%
as_tibble() %>%
set_names(.,
nm = .[1,] %>%
str_replace_all(., "[[:punct:]]|º", "") %>%
str_to_lower() %>%
str_replace_all(., "\\s+", "_")) %>%
slice(2)
if(ncol(dec_table) == 1){
md_table$decisao_texto <- pull(dec_table[1])
} else {
md_table$decisao_texto <- NA_character_
}
case_table <- md_table %>%
mutate(case_page = case_page,
dateOfAccess = Sys.Date()) %>%
select(data_do_acordao = "data_do_acordão", relator, decisao = "decisão", votacao = "votação", palavras_chave = descritores, meio_processual, sumario = "sumário", decisao_texto, one_of("decisão_texto_parcial", "decisão_texto_integral"), dateOfAccess, case_page)
print(case_table[,sample(1:ncol(case_table), 4)])
return(case_table)
Sys.sleep(runif(2,1,3))
})
beepr::beep(8)
## export it
save(relLx_data_raw,
file = "interm_data/raw_relLx_data.Rdata")
write.csv(relLx_data_raw,
file = "interm_data/raw_relLx_data.csv")
case_page <- metadata_relLx$case_page[3084]
con_test <- try(parsed_case_page <- case_page %>%
read_html(), silent = TRUE)
# if true, weak connection...wait 1 minute, and then reconnect and parse the HTML page
if(class(con_test) == "try-error") {
print("reconecting in 1 minute!")
Sys.sleep(60)
parsed_case_page <- case_page %>%
read_html()
}
parsed_case_page %>%
html_node(xpath = "//table") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2)
parsed_case_page %>%
html_node(xpath = "//table") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:$")) %>%
t() %>%
as_tibble()
parsed_case_page %>%
html_node(xpath = "//table") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:$")) %>%
t() %>%
as_tibble() %>%
set_names(.,
nm = .[1,] %>%
str_replace_all(., "[[:punct:]]|º", "") %>%
str_to_lower() %>%
str_replace_all(., "\\s+", "_")) %>%
slice(2) %>%
mutate_all(funs(str_replace_all(., "[[:cntrl:]]", "; ")))
### scrape the case details table
md_table <- parsed_case_page %>%
html_node(xpath = "//table") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:$")) %>%
t() %>%
as_tibble() %>%
set_names(.,
nm = .[1,] %>%
str_replace_all(., "[[:punct:]]|º", "") %>%
str_to_lower() %>%
str_replace_all(., "\\s+", "_")) %>%
slice(2) %>%
mutate_all(funs(str_replace_all(., "[[:cntrl:]]", "; ")))
parsed_case_page %>%
html_node(xpath = "//table[2]") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2) %>%
filter(str_detect(X1, "\\:")) %>%
t() %>%
as_tibble() %>%
set_names(.,
nm = .[1,] %>%
str_replace_all(., "[[:punct:]]|º", "") %>%
str_to_lower() %>%
str_replace_all(., "\\s+", "_")) %>%
slice(2)
browseURL(case_page)
parsed_case_page %>%
html_node(xpath = "//table[2]") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
select(1:2)
parsed_case_page %>%
html_node(xpath = "//table[2]") %>%
html_table(fill = TRUE) %>%
as_tibble()
parsed_case_page %>%
html_node(xpath = "//table[2]") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
filter(str_detect(X1, "\\:")) %>%
t()
parsed_case_page %>%
html_node(xpath = "//table[2]") %>%
html_table(fill = TRUE) %>%
as_tibble() %>%
filter(str_detect(X1, "\\:")) %>%
t() %>%
as_tibble()
arsed_case_page %>%
html_node(xpath = "//table[2]") %>%
html_table(fill = TRUE) %>%
as_tibble()
parsed_case_page %>%
html_node(xpath = "//table[2]") %>%
html_table(fill = TRUE) %>%
as_tibble()
View(parsed_case_page %>%
html_node(xpath = "//table[2]") %>%
html_table(fill = TRUE) %>%
as_tibble())
parsed_case_page %>%
html_node(xpath = "//table[2]") %>%
html_table(fill = TRUE)
q()

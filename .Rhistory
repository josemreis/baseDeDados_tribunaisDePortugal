remaining <- (N - (max_group * group_n))
## make the number sequence
result <- c(seq(1, (max_group * group_n), group_n), seq((max_group * group_n), N, remaining))
}
maximum_group(N = 11486)
maximum_group <- function(N , group_n = 30){
## get the maximum number of complete groups given group_n
max_group <- as.integer(N/group_n)
## get the remaining
remaining <- (N - (max_group * group_n))
## make the number sequence
result <- c(seq(1, (max_group * group_n), group_n), seq((max_group * group_n), N, remaining))
return(result)
}
maximum_group(N = 11486)
?as.integer
?round
## get the maximum number of complete groups given group_n
max_group <- as.integer(ceiling(N/group_n))
maximum_group <- function(N , group_n = 30){
## get the maximum number of complete groups given group_n
max_group <- as.integer(ceiling(N/group_n))
## get the remaining
remaining <- (N - (max_group * group_n))
## make the number sequence
result <- c(seq(1, (max_group * group_n), group_n), seq((max_group * group_n), N, remaining))
return(result)
}
maximum_group(N = 11486)
maximum_group <- function(N , group_n = 30){
## get the maximum number of complete groups given group_n
max_group <- as.integer(ceiling(N/group_n))
## get the remaining
remaining <- (N - (max_group * group_n))
## make the number sequence
result <- c(seq(1, (max_group * group_n), group_n), seq((max_group * group_n), N, remaining))
return(result)
}
maximum_group(N = 1186)
maximum_group(N = 11486)
maximum_group <- function(N , group_n = 30){
## get the maximum number of complete groups given group_n
max_group <- as.integer(ceiling(N/group_n))
## get the remaining
remaining <- (N - (max_group * group_n))
## make the number sequence
result <- c(seq(1, (max_group * group_n), group_n), seq((max_group * group_n), N, remaining))
return(result)
}
maximum_group(N = 11486)
maximum_group(N = 11486, group_n = 29)
maximum_group <- function(N , group_n = 29){
## get the maximum number of complete groups given group_n
max_group <- as.integer(ceiling(N/group_n))
## get the remaining
remaining <- (N - (max_group * group_n))
## make the number sequence
result <- c(seq(1, (max_group * group_n), group_n), seq((max_group * group_n), N, remaining))
return(result)
}
N
N <- 11486
group_n = 29
as.integer(ceiling(N/group_n))
## get the maximum number of complete groups given group_n
max_group <- as.integer(ceiling(N/group_n))
## get the remaining
remaining <- (N - (max_group * group_n))
max_group * group_n
group_n = 30
## get the maximum number of complete groups given group_n
max_group <- as.integer(ceiling(N/group_n))
(N - (max_group * group_n))
N
N/group_n
ceiling(N/group_n)
floor(N/group_n)
## get the maximum number of complete groups given group_n
max_group <- floor(N/group_n)
(N - (max_group * group_n))
group_n = 29
max_group <- floor(N/group_n)
## get the remaining
remaining <- (N - (max_group * group_n))
c(seq(1, (max_group * group_n), group_n), seq((max_group * group_n), N, remaining))
11484 - 11456
11486 - 11456
maxGroupSeq <- function(N, group_n = 30){
## get the maximum number of complete groups given group_n
max_group <- floor(N/group_n)
## get the remaining
remaining <- (N - (max_group * group_n))
## make the number sequence
result <- c(seq(1, (max_group * group_n), group_n), seq((max_group * group_n), N, remaining))
return(result)
}
maxGroupSeq(N = 11486)
maxGroupSeq(N = 11486, group_n = 30)
maxGroupSeq(N = 11486, group_n = 29)
11484 - 11456
maxGroupSeq(N = 11486, group_n = 30)
maxGroupSeq(N = 11486, group_n = 29)
maxGroupSeq(N = 11486, group_n = 30)
maxGroupSeq(N = 11486, group_n = 27)
maxGroupSeq(N = 11486, group_n = 31)
maxGroupSeq(N = 11486, group_n = 30)
maxGroupSeq(N = 11486, group_n = 28)
maxGroupSeq(N = 11486, group_n = 30)
seq(1, 11486, 30)
seq(1, 11486, 29)
map2_chr(base_url, seq(1, index_data$n[str_detect(index_data$docs,regex(inst_regex, ignore_case = TRUE))], 29), paste0)
seq(1, index_data$n[str_detect(index_data$docs,regex(inst_regex, ignore_case = TRUE))], 29)
index_data$n[str_detect(index_data$docs,regex(inst_regex, ignore_case = TRUE))]
inst_regex <- "Rel.*Coimbra"
index_data$n[str_detect(index_data$docs,regex(inst_regex, ignore_case = TRUE))]
inst_regex
index_data$n[str_detect(index_data$docs,regex(inst_regex, ignore_case = TRUE))]
index_table$n
scraper_casePages_bjd <- function(index_data = index_table,
inst_regex = "Lisboa"){
### define the relevant base url depending on the selected institution regex
base_url <- paste0(index_data$repo_url[str_detect(index_data$docs, regex(inst_regex, ignore_case = TRUE))], "&Start=")
### each sub-page of the repo, by default, contains 29 cases as well as the remaining. Generate a sequence from 1 to the last case in groups of 29, and past it with the base url
sub_pages <- map2_chr(base_url, seq(1, index_data$n[str_detect(index_data$docs,regex(inst_regex, ignore_case = TRUE))], 29), paste0)
### Now we loop across each sub-page and extract tables with the case page as well as metadata.
output <- map2_df(sub_pages, 1:length(sub_pages), function(sub_page, n){
cat(paste0("scraping page ", n, "\n\n"))
## check the internet conection, and wait if it is weak. If not, just parse the HTML page
con_test <- try(parsed_sub_page <- sub_page %>%
read_html(), silent = TRUE)
# if true, weak connection...wait 1 minute, and then reconnect and parse the HTML page
if(class(con_test) == "try-error") {
print("reconecting in 1 minute!")
Sys.sleep(60)
parsed_sub_page <- sub_page %>%
read_html()
}
## scrape the metadata of the cases in the sub-page
metadata <- parsed_sub_page %>%
html_node(xpath = "//td//table") %>%
html_table() %>%
as_tibble() %>%
subset(., nchar(PROCESSO > 2) & RELATOR != "N") %>%
mutate(case_page = parsed_sub_page %>%
html_nodes("td td font a") %>%
html_attr("href") %>%
paste0("http://www.dgsi.pt", .)) %>%
set_names(str_to_lower(names(.))) %>%
mutate(dateOfAccess = Sys.Date(),
institution = index_data$docs[str_detect(index_data$docs, regex(inst_regex, ignore_case = TRUE))],
`sessão` = mdy(`sessão`),
processo = as.character(processo),
descritor = str_replace_all(descritor, "[[:cntrl:]]", "; ")) %>%
select(inst = institution, data = "sessão",  proc = processo, relator, palavras_chave = descritor, everything())
print(sample_n(metadata, 3))
## rest time for the server
Sys.sleep(runif(5,3,7))
return(metadata)
})
}
index_table$n[str_detect(index_table$docs,regex(inst_regex, ignore_case = TRUE))]
seq(1, index_table$n[str_detect(index_table$docs,regex(inst_regex, ignore_case = TRUE))], 29)
base_url <- paste0(index_table$repo_url[str_detect(index_table$docs, regex(inst_regex, ignore_case = TRUE))], "&Start=")
### each sub-page of the repo, by default, contains 29 cases as well as the remaining. Generate a sequence from 1 to the last case in groups of 29, and past it with the base url
sub_pages <- map2_chr(base_url, seq(1, index_table$n[str_detect(index_table$docs,regex(inst_regex, ignore_case = TRUE))], 29), paste0)
sub_page <- sub_pages[397]
browseURL(sub_page)
## check the internet conection, and wait if it is weak. If not, just parse the HTML page
con_test <- try(parsed_sub_page <- sub_page %>%
read_html(), silent = TRUE)
parsed_sub_page %>%
html_node(xpath = "//td//table") %>%
html_table() %>%
as_tibble() %>%
subset(., nchar(PROCESSO > 2) & RELATOR != "N")
scraper_casePages_bjd <- function(index_table = index_table,
inst_regex = "Lisboa"){
### define the relevant base url depending on the selected institution regex
base_url <- paste0(index_table$repo_url[str_detect(index_table$docs, regex(inst_regex, ignore_case = TRUE))], "&Start=")
### each sub-page of the repo, by default, contains 29 cases as well as the remaining. Generate a sequence from 1 to the last case in groups of 29, and past it with the base url
sub_pages <- map2_chr(base_url, seq(1, index_table$n[str_detect(index_table$docs,regex(inst_regex, ignore_case = TRUE))], 29), paste0)
### Now we loop across each sub-page and extract tables with the case page as well as metadata.
output <- map2_df(sub_pages, 1:length(sub_pages), function(sub_page, n){
cat(paste0("scraping page ", n, "\n\n"))
## check the internet conection, and wait if it is weak. If not, just parse the HTML page
con_test <- try(parsed_sub_page <- sub_page %>%
read_html(), silent = TRUE)
# if true, weak connection...wait 1 minute, and then reconnect and parse the HTML page
if(class(con_test) == "try-error") {
print("reconecting in 1 minute!")
Sys.sleep(60)
parsed_sub_page <- sub_page %>%
read_html()
}
## scrape the metadata of the cases in the sub-page
metadata <- parsed_sub_page %>%
html_node(xpath = "//td//table") %>%
html_table() %>%
as_tibble() %>%
subset(., nchar(PROCESSO > 2) & RELATOR != "N") %>%
mutate(case_page = parsed_sub_page %>%
html_nodes("td td font a") %>%
html_attr("href") %>%
paste0("http://www.dgsi.pt", .)) %>%
set_names(str_to_lower(names(.))) %>%
mutate(dateOfAccess = Sys.Date(),
institution = index_table$docs[str_detect(index_table$docs, regex(inst_regex, ignore_case = TRUE))],
`sessão` = mdy(`sessão`),
processo = as.character(processo),
descritor = str_replace_all(descritor, "[[:cntrl:]]", "; ")) %>%
select(inst = institution, data = "sessão",  proc = processo, relator, palavras_chave = descritor, everything())
print(sample_n(metadata, 3))
## rest time for the server
Sys.sleep(runif(5,3,7))
return(metadata)
})
}
metadata_relCoimbra <- scraper_casePages_bjd(index_table = index_table,
inst_regex = "Rela.*Coimbra")
beepr::beep(8)
sub_page <- sub_page[397]
con_test <- try(parsed_sub_page <- sub_page %>%
read_html(), silent = TRUE)
# if true, weak connection...wait 1 minute, and then reconnect and parse the HTML page
if(class(con_test) == "try-error") {
print("reconecting in 1 minute!")
Sys.sleep(60)
parsed_sub_page <- sub_page %>%
read_html()
}
## scrape the metadata of the cases in the sub-page
metadata <- parsed_sub_page %>%
html_node(xpath = "//td//table") %>%
html_table() %>%
as_tibble() %>%
subset(., nchar(PROCESSO > 2) & RELATOR != "N") %>%
mutate(case_page = parsed_sub_page %>%
html_nodes("td td font a") %>%
html_attr("href") %>%
paste0("http://www.dgsi.pt", .)) %>%
set_names(str_to_lower(names(.))) %>%
mutate(dateOfAccess = Sys.Date(),
institution = index_table$docs[str_detect(index_table$docs, regex(inst_regex, ignore_case = TRUE))],
`sessão` = mdy(`sessão`),
processo = as.character(processo),
descritor = str_replace_all(descritor, "[[:cntrl:]]", "; ")) %>%
select(inst = institution, data = "sessão",  proc = processo, relator, palavras_chave = descritor, everything())
print(sample_n(metadata, nrow(metadata)/2))
scraper_casePages_bjd <- function(index_table = index_table,
inst_regex = "Lisboa"){
### define the relevant base url depending on the selected institution regex
base_url <- paste0(index_table$repo_url[str_detect(index_table$docs, regex(inst_regex, ignore_case = TRUE))], "&Start=")
### each sub-page of the repo, by default, contains 29 cases as well as the remaining. Generate a sequence from 1 to the last case in groups of 29, and past it with the base url
sub_pages <- map2_chr(base_url, seq(1, index_table$n[str_detect(index_table$docs,regex(inst_regex, ignore_case = TRUE))], 29), paste0)
### Now we loop across each sub-page and extract tables with the case page as well as metadata.
output <- map2_df(sub_pages, 1:length(sub_pages), function(sub_page, n){
cat(paste0("scraping page ", n, "\n\n"))
## check the internet conection, and wait if it is weak. If not, just parse the HTML page
con_test <- try(parsed_sub_page <- sub_page %>%
read_html(), silent = TRUE)
# if true, weak connection...wait 1 minute, and then reconnect and parse the HTML page
if(class(con_test) == "try-error") {
print("reconecting in 1 minute!")
Sys.sleep(60)
parsed_sub_page <- sub_page %>%
read_html()
}
## scrape the metadata of the cases in the sub-page
metadata <- parsed_sub_page %>%
html_node(xpath = "//td//table") %>%
html_table() %>%
as_tibble() %>%
subset(., nchar(PROCESSO > 2) & RELATOR != "N") %>%
mutate(case_page = parsed_sub_page %>%
html_nodes("td td font a") %>%
html_attr("href") %>%
paste0("http://www.dgsi.pt", .)) %>%
set_names(str_to_lower(names(.))) %>%
mutate(dateOfAccess = Sys.Date(),
institution = index_table$docs[str_detect(index_table$docs, regex(inst_regex, ignore_case = TRUE))],
`sessão` = mdy(`sessão`),
processo = as.character(processo),
descritor = str_replace_all(descritor, "[[:cntrl:]]", "; ")) %>%
select(inst = institution, data = "sessão",  proc = processo, relator, palavras_chave = descritor, everything())
print(sample_n(metadata, nrow(metadata)/2))
## rest time for the server
Sys.sleep(runif(5,3,7))
return(metadata)
})
}
### scrape the metadata of the cases ---> Relacao doe Coimbra
metadata_relCoimbra <- scraper_casePages_bjd(index_table = index_table,
inst_regex = "Rela.*Coimbra")
beepr::beep(8)
## export it
save(metadata_relCoimbra,
file = "interm_data/metadata_casos_relCoimbra.Rdata")
write.csv(metadata_relCoimbra,
file = "interm_data/metadata_casos_relCoimbra.csv")
### scrape the metadata of the cases ---> Relacao de Evora
metadata_relEvora <- scraper_casePages_bjd(index_table = index_table,
inst_regex = "Rela.*vora")
beepr::beep(8)
## export it
save(metadata_relEvora,
file = "interm_data/metadata_casos_relEvora.Rdata")
write.csv(metadata_relEvora,
file = "interm_data/metadata_casos_relEvora.csv")
### scrape the metadata of the cases ---> Relacao de Evora
metadata_reGuimar <- scraper_casePages_bjd(index_table = index_table,
inst_regex = "Rela.*guimar")
beepr::beep(8)
## export it
save(metadata_relGuimar,
file = "interm_data/metadata_casos_relGuimar.Rdata")
write.csv(metadata_relGuimar,
file = "interm_data/metadata_casos_relGuimar.csv")
metadata_relGuimar <- metadata_reGuimar
## export it
save(metadata_relGuimar,
file = "interm_data/metadata_casos_relGuimar.Rdata")
write.csv(metadata_relGuimar,
file = "interm_data/metadata_casos_relGuimar.csv")
ls()
ls()[str_detect(ls(), "metadata_rel")]
#### Join them and export
metadata_relacao <- do.call("rbind", list(ls()[str_detect(ls(), "metadata_rel")]))
#### Join them and export
metadata_relacao <- do.call("rbind", list(metadata_relLx, metadata_relPorto, metadata_relCoimbra, metadata_relEvora, metadata_relGuimar))
## export it
save(metadata_relacao,
file = "interm_data/metadata_casos_relTodas.Rdata")
write.csv(metadata_relacao,
file = "interm_data/metadata_casos_relTodas.csv")
length(unique(metadata_relacao$proc))
## rbinding all the dfs. Keep only the unique cases
metadata_relacao <- do.call("rbind", list(metadata_relLx, metadata_relPorto, metadata_relCoimbra, metadata_relEvora, metadata_relGuimar)) %>%
distinct(proc, .keep_all = TRUE)
## export it
save(metadata_relacao,
file = "interm_data/metadata_casos_relTodas.Rdata")
write.csv(metadata_relacao,
file = "interm_data/metadata_casos_relTodas.csv")
names(metadata_relacao)
metadata_relacao
## rbinding all the dfs. Keep only the unique cases
metadata_relacao <- do.call("rbind", list(metadata_relLx, metadata_relPorto, metadata_relCoimbra, metadata_relEvora, metadata_relGuimar)) %>%
distinct(proc, .keep_all = TRUE) %>%
arrange(desc(data))
head(metadata_relacao$inst)
## rbinding all the dfs. Keep only the unique cases
metadata_relacao <- do.call("rbind", list(metadata_relLx, metadata_relPorto, metadata_relCoimbra, metadata_relEvora, metadata_relGuimar)) %>%
distinct(proc, .keep_all = TRUE) %>%
arrange(desc(data)) %>%
rename(relacao = inst) %>%
mutate(relacao = str_extract(., regex("(?<=d(e|o)\\s{1,6}).*", ignore_case = TRUE)))
table(metadata_relacao, useNA = "always")
table(metadata_relacao$inst, useNA = "always")
## rbinding all the dfs. Keep only the unique cases
metadata_relacao <- do.call("rbind", list(metadata_relLx, metadata_relPorto, metadata_relCoimbra, metadata_relEvora, metadata_relGuimar)) %>%
distinct(proc, .keep_all = TRUE) %>%
arrange(desc(data)) %>%
rename(relacao = inst) %>%
mutate(relacao = str_extract_all(., regex("(?<=Relação de ).*", ignore_case = TRUE)))
head(metadata_relacao$inst)
require(data.table)
metadata_relacao %>%
as.data.table()
metadata_rel <- as.data.table(metadata_relacao)
t <- metadata_rel[, inst := str_extract_all(inst, regex("(?<=Relação de ).*", ignore_case = TRUE))]
t <- metadata_rel[, inst := str_extract_all(inst, regex("(?<=Relação de ).*", ignore_case = TRUE))]
t <- metadata_rel[, inst := str_extract(inst, regex("(?<=Relação de ).*", ignore_case = TRUE))]
head(t$inst)
t <- metadata_rel[, inst := str_extract(inst, regex("(?<=de\\s{1,6}).*", ignore_case = TRUE))]
head(t$inst)
as_tibble(t)
t <- metadata_rel[, inst := str_extract(inst, regex("rel.*", ignore_case = TRUE))]
head(t$inst)
as_tibble(t)
metadata_rel
metadata_relacao
View(metadata_rel)
metadata_rel <- as.data.table(metadata_relacao)
metadata_rel[, inst := str_extract(inst, regex("rel.*", ignore_case = TRUE))]
View(metadata_rel)
metadata_rel <- as.data.table(metadata_relacao)
## rbinding all the dfs. Keep only the unique cases
metadata_rel <- do.call("rbind", list(metadata_relLx, metadata_relPorto, metadata_relCoimbra, metadata_relEvora, metadata_relGuimar)) %>%
distinct(proc, .keep_all = TRUE) %>%
arrange(desc(data)) %>%
rename(relacao = inst)
## clean up the relacao variable, keep only city name. Using data.table for speedness sake.
metadata_rel <- as.data.table(metadata_relacao)
##
metadata_rel[, relacao := str_extract(inst, regex("(?<=de\\s{1,6}|do\\s{1,6}).*?(?=$)", ignore_case = TRUE))]
View(metadata_rel)
## rbinding all the dfs. Keep only the unique cases
metadata_rel <- do.call("rbind", list(metadata_relLx, metadata_relPorto, metadata_relCoimbra, metadata_relEvora, metadata_relGuimar)) %>%
distinct(proc, .keep_all = TRUE) %>%
arrange(desc(data)) %>%
rename(relacao = inst)
View(metadata_rel)
## clean up the relacao variable, keep only city name. Using data.table for speedness sake.
##  turn to dt
metadata_rel <- as.data.table(metadata_relacao)
## clean the variable up
metadata_rel[, relacao := str_extract(relacao, regex("(?<=de\\s{1,6}|do\\s{1,6}).*?(?=$)", ignore_case = TRUE))]
View(metadata_rel)
## rbinding all the dfs. Keep only the unique cases
metadata_rel <- do.call("rbind", list(metadata_relLx, metadata_relPorto, metadata_relCoimbra, metadata_relEvora, metadata_relGuimar)) %>%
distinct(proc, .keep_all = TRUE) %>%
arrange(desc(data)) %>%
rename(relacao = inst)
metadata_rel
as.data.table(metadata_relacao)
## clean the variable up
metadata_rel[, inst := str_extract(relacao, regex("(?<=de\\s{1,6}|do\\s{1,6}).*?(?=$)", ignore_case = TRUE))]
metadata_rel <- as_tibble(metadata_rel)
View(metadata_rel)
class(metadata_rel)
## clean up the relacao variable, keep only city name. Using data.table for speedness sake.
##  turn to dt
metadata_rel <- as.data.table(metadata_rel)
## clean the variable up
metadata_rel[, relacao := str_extract(relacao, regex("(?<=de\\s{1,6}|do\\s{1,6}).*?(?=$)", ignore_case = TRUE))]
View(metadata_rel)
## clean the variable up
metadata_rel[, relacao := str_extract(relacao, regex("(?<=de\\s{1,6}|do\\s{1,6})[A-Z][a-z]+(?=$)", ignore_case = TRUE))]
View(metadata_rel)
## rbinding all the dfs. Keep only the unique cases
metadata_rel <- do.call("rbind", list(metadata_relLx, metadata_relPorto, metadata_relCoimbra, metadata_relEvora, metadata_relGuimar)) %>%
distinct(proc, .keep_all = TRUE) %>%
arrange(desc(data)) %>%
rename(relacao = inst)
## clean up the relacao variable, keep only city name. Using data.table for speedness sake.
##  turn to dt
metadata_rel <- as.data.table(metadata_rel)
## clean the variable up
metadata_rel[, relacao := str_extract(relacao, regex("(?<=de\\s{1,6}|do\\s{1,6})[A-Z][a-z]+(\\s+)?(?=$)", ignore_case = TRUE))]
View(metadata_rel)
## rbinding all the dfs. Keep only the unique cases
metadata_rel <- do.call("rbind", list(metadata_relLx, metadata_relPorto, metadata_relCoimbra, metadata_relEvora, metadata_relGuimar)) %>%
distinct(proc, .keep_all = TRUE) %>%
arrange(desc(data)) %>%
rename(relacao = inst)
View(metadata_rel)
## clean the variable up
metadata_rel[, relacao := str_extract(relacao, regex("(?<=ção\\s{1,6}de\\s{1,6}|ção\\s{1,6}do\\s{1,6})[A-Z][a-z]+(\\s+)?(?=$)", ignore_case = TRUE))]
## rbinding all the dfs. Keep only the unique cases
metadata_rel <- do.call("rbind", list(metadata_relLx, metadata_relPorto, metadata_relCoimbra, metadata_relEvora, metadata_relGuimar)) %>%
distinct(proc, .keep_all = TRUE) %>%
arrange(desc(data)) %>%
rename(relacao = inst)
## clean up the relacao variable, keep only city name. Using data.table for speedness sake.
##  turn to dt
metadata_rel <- as.data.table(metadata_rel)
## clean the variable up
metadata_rel[, relacao := str_extract(relacao, regex("(?<=ção\\s{1,6}de\\s{1,6}|ção\\s{1,6}do\\s{1,6})[A-Z][a-z]+(\\s+)?(?=$)", ignore_case = TRUE))]
View(metadata_rel)
ue cases
metadata_rel <- do.call("rbind", list(metadata_relLx, metadata_relPorto, metadata_relCoimbra, metadata_relEvora, metadata_relGuimar)) %>%
distinct(proc, .keep_all = TRUE) %>%
arrange(desc(data)) %>%
rename(relacao = inst)
## clean up the relacao variable, keep only city name. Using data.table for speedness sake.
##  turn to dt
metadata_rel <- as.data.table(metadata_rel)
## clean the variable up
metadata_rel[, relacao := str_extract(relacao, regex("(?<=ção\\s{1,6}de\\s{1,6}|ção\\s{1,6}do\\s{1,6}).*", ignore_case = TRUE))]
View(metadata_rel)
## rbinding all the dfs. Keep only the unique cases
metadata_rel <- do.call("rbind", list(metadata_relLx, metadata_relPorto, metadata_relCoimbra, metadata_relEvora, metadata_relGuimar)) %>%
distinct(proc, .keep_all = TRUE) %>%
arrange(desc(data)) %>%
rename(relacao = inst)
## clean up the relacao variable, keep only city name. Using data.table for speedness sake.
##  turn to dt
metadata_rel <- as.data.table(metadata_rel)
## clean the variable up
metadata_rel[, relacao := str_trim(str_extract(relacao, regex("(?<=ção\\s{1,6}de\\s{1,6}|ção\\s{1,6}do\\s{1,6}).*", ignore_case = TRUE)))]
## coerce it back into tibble
metadata_rel <- as_tibble(metadata_rel)
metadata_rel
## export it
save(metadata_rel,
file = "data/1_metadata_casos_relTodas.Rdata")
write.csv(metadata_rel,
file = "data/1_metadata_casos_relTodas.csv")
t <- head(metadata_rel)
t
t$palavras_chave
t %>% separate(palavras_chave)
t %>% separate(palavras_chave, c(paste("palavra_chave_", 1:max(length(str_detect(.$palavras_chave, ";"))))))
t %>% separate(palavras_chave, c(paste("palavra_chave_", 1:max(length(str_detect(.$palavras_chave, ";")))))) %>% View()
t %>% separate(palavras_chave, c(paste("palavra_chave_", 1:max(length(str_detect(.$palavras_chave, ";"))))), "(\\s+)?;(\\s+)?") %>% View()
t %>% separate(palavras_chave, c(paste("palavra_chave", 1:max(length(str_detect(.$palavras_chave, ";"))), collapse = "_")), "(\\s+)?;(\\s+)?") %>% View()
t %>% separate(palavras_chave, c(paste0("palavra_chave_", 1:max(length(str_detect(.$palavras_chave, ";"))))), "(\\s+)?;(\\s+)?") %>% View()
## rbinding all the dfs. Keep only the unique cases
metadata_rel <- do.call("rbind", list(metadata_relLx, metadata_relPorto, metadata_relCoimbra, metadata_relEvora, metadata_relGuimar)) %>%
distinct(proc, .keep_all = TRUE) %>%
arrange(desc(data)) %>%
rename(relacao = inst) %>% ## split up the keyword var
separate(palavras_chave, c(paste0("palavra_chave_", 1:max(length(str_detect(.$palavras_chave, ";"))))), "(\\s+)?;(\\s+)?")
max(map_int(metadata_rel$palavras_chave, length, str_split, ";"))
max(map_int(metadata_rel$palavras_chave, length(str_split(., ";")[[1]])))
max(map_int(metadata_rel$palavras_chave, function(x) length(str_split(x, ";")[[1]])))
## clean up the relacao variable, keep only city name. Using data.table for speedness sake.
##  turn to dt
metadata_rel <- as.data.table(metadata_rel)
rm(list=ls())
load("C:/Dropbox/Current projects/other_projects/R_project/baseDeDados_tribunaisDePortugal/getAndClean/data/1_metadata_casos_relTodas.Rdata")
q()
